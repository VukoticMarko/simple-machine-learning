{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb69aabe-9160-45f3-9bd2-d6df26a78211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dd22781-e222-411f-baf7-596eb5817f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the dataset of SMS messages\n",
    "df = pd.read_table('SMSSPamCollection', header=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38794499-43d9-47c7-8240-8ed2b9684291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       5572 non-null   object\n",
      " 1   1       5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "None\n",
      "      0                                                  1\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d45909f5-966d-40ca-85c9-1e69149781d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class distribution\n",
    "classes = df[0]\n",
    "print(classes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af481c7a-1fca-42b2-8798-87dd453e9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert class labels to binary values, 0 = ham and 1 = spam\n",
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(classes)\n",
    "\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "931a8d9c-7810-45df-900e-ef11b9d01154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     Go until jurong point, crazy.. Available only ...\n",
      "1                         Ok lar... Joking wif u oni...\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3     U dun say so early hor... U c already then say...\n",
      "4     Nah I don't think he goes to usf, he lives aro...\n",
      "5     FreeMsg Hey there darling it's been 3 week's n...\n",
      "6     Even my brother is not like to speak with me. ...\n",
      "7     As per your request 'Melle Melle (Oru Minnamin...\n",
      "8     WINNER!! As a valued network customer you have...\n",
      "9     Had your mobile 11 months or more? U R entitle...\n",
      "10    I'm gonna be home soon and i don't want to tal...\n",
      "11    SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12    URGENT! You have won a 1 week FREE membership ...\n",
      "13    I've been searching for the right words to tha...\n",
      "14                  I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15    XXXMobileMovieClub: To use your credit, click ...\n",
      "16                           Oh k...i'm watching here:)\n",
      "17    Eh u remember how 2 spell his name... Yes i di...\n",
      "18    Fine if thats the way u feel. Thats the way ...\n",
      "19    England v Macedonia - dont miss the goals/team...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Store the SMS message data\n",
    "text_messages = df[1]\n",
    "print(text_messages[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ef480f6-db54-4cfc-9263-7df7cbcdac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions to replace email addresses, URLs, phone numbers and other sensitive info\n",
    "\n",
    "# Replace email addresses with 'email'\n",
    "processed = text_messages.str.replace(r'^.+@[^\\.].*\\.[a-z]{2,}$',\n",
    "                                 'emailaddress')\n",
    "\n",
    "# Replace URLs with 'webaddress'\n",
    "processed = processed.str.replace(r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$',\n",
    "                                  'webaddress')\n",
    "\n",
    "# Replace money symbols with 'moneysymb' (£ can by typed with ALT key + 156)\n",
    "processed = processed.str.replace(r'£|\\$', 'moneysymb')\n",
    "    \n",
    "# Replace 10 digit phone numbers (formats include paranthesis, spaces, no spaces, dashes) with 'phonenumber'\n",
    "processed = processed.str.replace(r'^\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$',\n",
    "                                  'phonenumbr')\n",
    "    \n",
    "# Replace numbers with 'numbr'\n",
    "processed = processed.str.replace(r'\\d+(\\.\\d+)?', 'numbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8082a77-d48d-47cb-90a3-7b403d2f5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation as it's not useful\n",
    "processed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n",
    "\n",
    "# Replace whitespace between terms with a single space\n",
    "processed = processed.str.replace(r'\\s+', ' ')\n",
    "\n",
    "# Remove leading and trailing whitespace\n",
    "processed = processed.str.replace(r'^\\s+|\\s+?$', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3515b5c-78d9-41c3-81b5-3146d762d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     go until jurong point, crazy.. available only ...\n",
      "1                         ok lar... joking wif u oni...\n",
      "2     free entry in 2 a wkly comp to win fa cup fina...\n",
      "3     u dun say so early hor... u c already then say...\n",
      "4     nah i don't think he goes to usf, he lives aro...\n",
      "5     freemsg hey there darling it's been 3 week's n...\n",
      "6     even my brother is not like to speak with me. ...\n",
      "7     as per your request 'melle melle (oru minnamin...\n",
      "8     winner!! as a valued network customer you have...\n",
      "9     had your mobile 11 months or more? u r entitle...\n",
      "10    i'm gonna be home soon and i don't want to tal...\n",
      "11    six chances to win cash! from 100 to 20,000 po...\n",
      "12    urgent! you have won a 1 week free membership ...\n",
      "13    i've been searching for the right words to tha...\n",
      "14                  i have a date on sunday with will!!\n",
      "15    xxxmobilemovieclub: to use your credit, click ...\n",
      "16                           oh k...i'm watching here:)\n",
      "17    eh u remember how 2 spell his name... yes i di...\n",
      "18    fine if thats the way u feel. thats the way ...\n",
      "19    england v macedonia - dont miss the goals/team...\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Change words to lower case - ex. Hello, HELLO, hello are now the same word\n",
    "processed = processed.str.lower()\n",
    "print(processed[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ae48a85-c19e-4d03-b196-9f25cc5740e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove stop words from text messages\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    term for term in x.split() if term not in stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6571b1c-7266-4bbb-9a74-314e08a6fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove word stems using a Porter stemmer\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "processed = processed.apply(lambda x: ' '.join(\n",
    "    ps.stem(term) for term in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cd3fa25-96a9-4938-b95c-414bb78f6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Create bag-of-words\n",
    "all_words = []\n",
    "\n",
    "for message in processed:\n",
    "    words = word_tokenize(message)\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0465690-8fb5-47b0-9514-69513d0852b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 8921\n",
      "Most common words: [('.', 4759), (',', 1939), ('?', 1550), ('!', 1397), ('...', 1146), ('u', 1138), ('&', 922), (';', 768), (':', 722), ('i', 715), ('..', 697), ('call', 644), (\"'\", 535), (')', 499), ('2', 478)]\n"
     ]
    }
   ],
   "source": [
    "# Print the total number of words and the 15 most common words\n",
    "print('Number of words: {}'.format(len(all_words)))\n",
    "print('Most common words: {}'.format(all_words.most_common(15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e150e7f7-0389-42ff-8705-9032d91c50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the x most common words as features\n",
    "word_features = list(all_words.keys())[:4500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5356979-901e-4913-a016-84b51f744ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "jurong\n",
      "point\n",
      ",\n",
      "crazy\n",
      "..\n",
      "avail\n",
      "bugi\n",
      "n\n",
      "great\n",
      "world\n",
      "la\n",
      "e\n",
      "buffet\n",
      "...\n",
      "cine\n",
      "got\n",
      "amor\n",
      "wat\n"
     ]
    }
   ],
   "source": [
    "# The find_features function will determine which of the x word features are contained in the review\n",
    "def find_features(message):\n",
    "    words = word_tokenize(message)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "\n",
    "    return features\n",
    "\n",
    "# Test\n",
    "features = find_features(processed[0])\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ff27a75-5806-416f-8cf6-71b15480ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a seed for reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "messages = list(zip(processed, Y))  # Convert to a list\n",
    "np.random.shuffle(messages)\n",
    "\n",
    "# Call find_features function for each SMS message\n",
    "featuresets = [(find_features(text), label) for (text, label) in messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a78632f8-62b9-4094-ba3e-5b957972cc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4179\n",
      "1393\n"
     ]
    }
   ],
   "source": [
    "# Train/Test\n",
    "from sklearn import model_selection\n",
    "\n",
    "# split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)\n",
    "\n",
    "print(len(training))\n",
    "print(len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7670b9e-1be9-4166-9b14-5c0ead5c3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 98.42067480258436\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# Train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# Test\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "503ae9bd-6df6-4ff1-a1a4-cdc3c0a997ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Neighbors Accuracy: 90.8829863603733\n",
      "Decision Tree Accuracy: 95.83632447954056\n",
      "Random Forest Accuracy: 97.27207465900933\n",
      "Logistic Regression Accuracy: 98.06173725771716\n",
      "SGD Classifier Accuracy: 98.27709978463747\n",
      "Naive Bayes Accuracy: 97.84637473079684\n",
      "SVM Linear Accuracy: 98.42067480258436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Define models to train\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter = 100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel = 'linear')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "\n",
    "for name, model in models:\n",
    "    nltk_model = SklearnClassifier(model)\n",
    "    nltk_model.train(training)\n",
    "    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n",
    "    print(\"{} Accuracy: {}\".format(name, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94690044-bb5b-4f34-a4a4-b30c6aa9d32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble methods - Voting classifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "names = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\", \"SGD Classifier\",\n",
    "         \"Naive Bayes\", \"SVM Linear\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(max_iter=100),\n",
    "    MultinomialNB(),\n",
    "    SVC(kernel='linear')\n",
    "]\n",
    "\n",
    "# Create a list of estimators (list of tuples)\n",
    "models = list(zip(names, classifiers))  # Convert zip object to list\n",
    "\n",
    "# Create a VotingClassifier\n",
    "voting_clf = VotingClassifier(estimators=models, voting='hard', n_jobs=-1)\n",
    "\n",
    "# Wrap the VotingClassifier in an SklearnClassifier\n",
    "nltk_ensemble = SklearnClassifier(voting_clf)\n",
    "\n",
    "# Train the VotingClassifier using the training data\n",
    "nltk_ensemble.train(training)\n",
    "\n",
    "# Evaluate the ensemble\n",
    "accuracy = nltk.classify.accuracy(nltk_ensemble, testing) * 100\n",
    "print(\"Voting Classifier Accuracy: {:.2f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e42e2-8d82-47b9-beb6-bf6d0bb3383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class label prediction for testing set\n",
    "txt_features, labels = zip(*testing)\n",
    "\n",
    "prediction = nltk_ensemble.classify_many(txt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24d5b6-70ae-4e8d-ab4c-a411ec5c5bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a confusion matrix and a classification report\n",
    "print(classification_report(labels, prediction))\n",
    "\n",
    "pd.DataFrame(\n",
    "    confusion_matrix(labels, prediction),\n",
    "    index = [['actual', 'actual'], ['ham', 'spam']],\n",
    "    columns = [['predicted', 'predicted'], ['ham', 'spam']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d78b1-992b-44bd-8eab-5f081e2eb340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
