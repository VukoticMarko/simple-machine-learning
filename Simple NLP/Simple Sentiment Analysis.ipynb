{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fa32d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\blast\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\blast\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\blast\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\blast\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\blast\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\blast\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772fbfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download() # Dowload 'popular' packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d8daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 2000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "             for fileid in movie_reviews.fileids(category)]\n",
    "\n",
    "# Shuffle the documents so we don't have all positive/negative reviews in a sequence\n",
    "random.shuffle(documents)\n",
    "\n",
    "print('Number of Documents: {}'.format(len(documents)))\n",
    "\n",
    "# Print specific review\n",
    "#print('First Review: {}'.format(documents[1]))\n",
    "\n",
    "all_words = []\n",
    "for w in movie_reviews.words():\n",
    "    all_words.append(w.lower())\n",
    "\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "# Prints to analyse dataset\n",
    "#print('Most common words: {}'.format(all_words.most_common(15)))\n",
    "#print('The word happy: {}'.format(all_words[\"happy\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f5affcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39768\n"
     ]
    }
   ],
   "source": [
    "# We'll use the 4000 most common words as features\n",
    "print(len(all_words)) # of unique words\n",
    "word_features = list(all_words.keys())[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69181e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a document\n",
    "# The function checks whether each of the 4000 feature words is present in the document\n",
    "def find_features(document):\n",
    "    \n",
    "    words = set(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words) # Boolean: True if word is present, False otherwise\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "# Test the feature extraction on a specific negative review\n",
    "features = find_features(movie_reviews.words('neg/cv000_29416.txt'))\n",
    "# Print only the feature words that are present in the document\n",
    "for key, value in features.items():\n",
    "    if value == True:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1c5d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset of features for all documents (Feature Extraction)\n",
    "# Each entry is a tuple: (feature dictionary, category)\n",
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dcdfaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn import for train/test split\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Define a seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# Split the data into training and testing datasets\n",
    "training, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0865a2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: 78.4 %\n"
     ]
    }
   ],
   "source": [
    "# We can use sklearn algorithms in NLTK\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SklearnClassifier(SVC(kernel = 'linear'))\n",
    "\n",
    "# Train the model on the training data\n",
    "model.train(training)\n",
    "\n",
    "# Test on the testing dataset\n",
    "accuracy = nltk.classify.accuracy(model, testing)*100\n",
    "print(\"SVC Accuracy: {} %\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ac112dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Review Sentiment: pos\n",
      "Custom Review Sentiment: neg\n",
      "Custom Review Sentiment Mixed: neg\n"
     ]
    }
   ],
   "source": [
    "# Predict sentiment for a custom review (for testing)\n",
    "def predict_sentiment(review):\n",
    "    words = review.lower().split()\n",
    "    features = find_features(words)\n",
    "    return model.classify(features)\n",
    "\n",
    "# Test with a custom review\n",
    "custom_review = \"The movie was fantastic, with a thrilling plot and excellent acting.\"\n",
    "sentiment = predict_sentiment(custom_review)\n",
    "print(f\"Custom Review Sentiment: {sentiment}\")\n",
    "\n",
    "custom_review_2 = \"The movie was a complete waste of time, very boring and poorly made.\"\n",
    "sentiment_2 = predict_sentiment(custom_review_2)\n",
    "print(f\"Custom Review Sentiment: {sentiment_2}\")\n",
    "\n",
    "custom_review_3_mixed = \"Wow I really liked the acting and the actors but the plot was horrible.\"\n",
    "sentiment_3 = predict_sentiment(custom_review_3_mixed)\n",
    "print(f\"Custom Review Sentiment Mixed: {sentiment_3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
